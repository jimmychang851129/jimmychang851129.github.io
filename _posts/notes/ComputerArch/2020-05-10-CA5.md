---
layout: post
title:  "Virtual Memory"
date:   2019-05-08 21:44:00
categories: Computer-Architecture
tags: Course
---

## Virtual Memory

### Main memory and Disk

- 資料大部分存在disk，只有部分需要時存在Main memory，再取更少部分放置到cache，因此需要有memory跟disk的控管、對應由OS,hardware共同決定
- 從disk搬資料到memory不會像cache那麼小(一個block)，而是以page為單位(因為disk到memory速度極慢，而且兩者儲存空間都不小，所以一次可以移更多資料

### Virtual Memory用途

1. mapping of Program address and OS memory address: 因為main memory跟disk的機制跟cache依樣。multi-tasking memory可能會滿，此時會把一些program踢出main memory丟到disk，那下次輪到此program時回來放到memory位置可能和當初的memory位置不同，所以要有virtual memory的mapping幫助程式找到對應的OS memory address。virtual address會紀錄當今對應的OS memory address。
2. security issue，可以規範程式只能access依定範圍的memory。
3. 讓使用者看到的space比較大(virtual memory看起來範圍比實際memory範圍大，因為virtual memory有處理disk跟memory傳遞資料的機制)，等於說讓有些virtual memory address對應到disk空間，virtual memory本身對應physical memory也可以是多對一，但沒有必要，後面會用page table來對應(而且是per process一個page table)，所以實務上是1對1。所以可以讓virtual memory看起來比較大

當virtual memory對應的memory address不再main memory裡面，那就是page fault(memory level的cache miss))


![Imgur](https://i.imgur.com/lTO4Te4.png)


#### Virtual page / Physical page address

page offset 使用的bit可以得知一個page多大<br />
EX: 4K page,代表有12bits的page offset

page number長度virtual page 通常比 physical page大，所以整體而言，virtual address比physical memory address大，因此有traslation機制(translate virtual page address to physical address)

| Vritual page | Virtual page number | page offset(決定page有多大(可以容納多少byte)) |
| -------- | -------- | -------- |
| Physical memory     | physical page number     | page offset(決定page有多大(可以容納多少byte))     |

EX: 4KB pages: 則page offset 有12 bits，用12 bits來定位這個4KB pages上的任何一個點

### Page Table

- virtual memory address 和 physical memory address間的translation(mapping)
- Array of page table entry
- index: virtual page number, value: physical address，再加上offset就可以得到地址(offset virtual page和physical page相同)
- 每個process都會有自己的page tables，page tables會擺在main memory裡面(page table register會指向page table位置) 
- page table entry也包含status bit(valid bit(reference bit), dirty bit)
- 如果virtual address指向的page不在main memory，page table entry會指向swap space(process專有，每個process都會有自己的swap space)
- 若對應的physical address不再memory，則valid bit = 0，如果在main memory，則valid bit = 1

### Page table replacement & writes

- associate cache方式來增進main memory運用(disk讀取速度太慢)
- 使用改良的LRU(Least recently used)來決定要把哪個memory放回disk
- reference bit為page table的status bit(相當於valid bit)
- 當memory addr被存取時，reference bit設成1，定時的把所有memory addr的reference bit變回0，當memory滿時，把reference bit為0的移掉改放新的memory block，不用counter，因為counter可能會overflow。
- 採用write-back，因為disk讀寫太慢

### TLB

virtual memory需要map virtual address to physicall address，需要額外memory reference，這個很浪費時間

1. 需要先去讀page table看virtual address的對應，page table存在main memory，讀取也要花點時間
2. 讀到physical address時，還要去access physical address(好一點在main memory，慘一點在disk )
3. TLB是所有process共用，不是一個process一個
4. TLB每次context switch都會清空(因為每個process的virtual address都不同)
5. dirty bits來取代page table的dirty bits(因為memory access速度慢)，不然就要變成每次有改physical address內部值都要回去page table寫dirty bits(但memory access太久)

Access Page table Entry也有 temporal locality的現象，如現在讀PTE的某個entry，附近周圍幾個entry也很有可能在短時間內被讀到。Spatial locality狀況還好，因為一個page就已經夠大了。

因此我們再加一個cache TLB(Translation look-aside buffer)存最近被access到的PTE entry存到TLB這個cache(Buffer)。這樣我們access virtual address時可以先去看TLB看看Entry有沒有存在裡面，有的話就可以少一次memory address(不用去main memory access PTE)。

通常會存16-512個PTE entry，依樣有valid,dirty bits之類的，寫回main memory(PTE)的機制

![Imgur](https://i.imgur.com/AI4ykNL.png)

#### TLB miss

去讀PTE，把該physical address讀出來，並把physical address寫進TLB

如果physical address在disk，那也會把他先搬到main memory，更新PTE，然後才寫到TLB

#### Page Fault handler

如果今天physical address也不在memory，就會呼叫這個handler，基本上就是決定要丟掉哪個memory block回disk，讓新的block寫進memory

### Virtually / physically address cache

physical / virtual address在cache上的整合

#### Physically addressed cache

cache紀錄用physical address，這樣在用virtual address時要先去TLB找對應的physical address再去檢查cache裡有沒有
 
#### Virtually addressed cache

用virtual address index cache，就不用TLB access，直接比對virtual address有沒有在cache裡。

缺點:
Aliasing: 在multi task中，兩個process可能會共用physical address，但對應到兩個process不同的virtual address，導致TLB紀錄會變成兩筆: 兩個process各自的virtual address對應到同個data。當process A修改該data時，process B沒辦法得到shared data，因為他有cache住，在cache中有另一比entry為他的virtual address對應到舊資料，不會去讀到process A的新值。


以下為virtually address cache示意圖(cache內部狀況)
如圖，因為兩process的virtual address不同，但都對應到相同physical addr(0xdeadbeef)，所以cache內變成兩筆記錄。原本0xdeadbeef值為3，process A把它改成5，但只改到自己的cache entry。process B access時，仍access到舊的值，不會收到5。

| Process | virtual address | data / physical addr |
| -------- | -------- | -------- |
| Process A | 0x1234 | 3 -> 5 / 0xdeadbeef |
| Process B     | 0xabcd     | 3 / 0xdeadbeef |


[aliasing explanation](https://www.youtube.com/watch?v=Tg6ID2uWjuY)

##### 複習

index: 在cache中，決定這塊資料寫進哪個cache block

tag: 因為memory cache是多對一，所以同個index有多個memory block可能寫入，用tag紀錄是哪個memory block

memory address為tag + index + offset

### Conclusion

virtual address記憶體存取狀況

offset不用去TLB，offset virtual address跟physical address相同

此為physically cached，步驟:<br />
1. 先去TLB做address轉換，如果TLB miss就會去page table取physical address，如果TLB有就不用去page table了
3. 去cache看該physical address在不在cache內(檢查index/tag)
4. access cache data or memory data

資料不可能在cache但不在memory

![Imgur](https://i.imgur.com/Lhg4mcg.png)

#### Block placement

- Direct mapped
- n-way set associative
- full associative

越高associativity可以減少miss rate，但compare的cost越貴，等於同個index有存很多block，要查在這index內每個block的physical address index/tag

#### Replacement

- LRU(least recently used)
- random(隨機踢出cache)
- Virtual memory(LRU with periodic reset)

#### Write policy

- write-through:每次修改都寫回memory
- write-back:被踢出cache才寫回memory
- write-buffer: 看時機寫出去

#### Source of miss

- Compulsory miss: 剛開始沒有cache(valid bit = 0)
- Capacity miss: cache滿了
- Conflict miss: non fully associate時，index有其他block了
